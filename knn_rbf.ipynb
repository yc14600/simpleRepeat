{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import bottleneck as bn\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import torch.multiprocessing as mp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"taskset -p 0xff %d\" % os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBFkernel():\n",
    "    def __init__(self,var_s,length_scale, var_n=0.):\n",
    "        self.var_s = var_s\n",
    "        self.var_n = var_n\n",
    "        self.inv_lscale = -0.5/length_scale\n",
    "    \n",
    "    def cov(self, tX, X):\n",
    "        k1 = np.sum(tX**2,1).reshape(-1,1)\n",
    "        k2 = np.repeat(np.sum(X**2,1).reshape(1,-1),tX.shape[0],axis=0)\n",
    "        k = k1+k2-2*np.matmul(tX,X.transpose())\n",
    "        k = self.var_s*np.exp(k*self.inv_lscale)\n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self,knl,K,num_job=8):\n",
    "        #super(KNN, self).__init__()\n",
    "        self.knl = knl\n",
    "        self.K = K\n",
    "        self.num_job = num_job\n",
    "    def set_affinity_on_worker(self):\n",
    "        \"\"\"When a new worker process is created, the affinity is set to all CPUs\"\"\"\n",
    "        #print(\"I'm the process %d, setting affinity to all CPUs.\" % os.getpid())\n",
    "        os.system(\"taskset -p 0xff %d\" % os.getpid())\n",
    "\n",
    "    def Klargest(self, a):\n",
    "        return np.argpartition(a, -self.K)[-self.K:]\n",
    "        \n",
    "    def Nnbrs(self, cor):\n",
    "        pool = mp.Pool(self.num_job)\n",
    "        nbr_ids=[None]*cor.shape[0]\n",
    "        for i in range(len(nbr_ids)):\n",
    "            nbr_ids[i]=pool.apply_async(self.Klargest, args=(cor[i],))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        nbr_ids = [ni.get() for ni in nbr_ids]\n",
    "        return np.vstack(nbr_ids)\n",
    "    \n",
    "    def assignLbl(self, nbr_lbs):\n",
    "        C = nbr_lbs.max()+1\n",
    "        camp = np.tile(np.array(range(0,C)),self.K).reshape(self.K,-1)\n",
    "        return np.argsort((np.tile(nbr_lbs.reshape(-1,1),C)==camp).sum(axis=0))[-1]\n",
    "    \n",
    "    def predict(self,nbr_ids,nbr_lbs):\n",
    "        pool = mp.Pool(self.num_job)\n",
    "        y = [None]*nbr_ids.shape[0]\n",
    "        for i in range(nbr_ids.shape[0]):\n",
    "            y[i] = pool.apply_async(self.assignLbl, args=(nbr_lbs[i],))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        y = [ni.get() for ni in y]\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def fit_predict(self, testX, X, Y, batch_size=100):\n",
    "        \n",
    "        #C = Y.max()+1\n",
    "        #self.camp = np.tile(np.array(range(0,C)),self.K).reshape(self.K,-1)\n",
    "        \n",
    "        B = testX.shape[0]/batch_size\n",
    "        if B*batch_size < testX.shape[0]:\n",
    "            B+=1\n",
    "        nbrs = np.zeros((testX.shape[0],self.K),dtype=int)\n",
    "        py = np.zeros(testX.shape[0],dtype=int)\n",
    "        for b in range(B):\n",
    "            uper = min((b+1)*batch_size, testX.shape[0])\n",
    "            print b,uper\n",
    "            tX = testX[b*batch_size:uper]\n",
    "            cor = self.knl.cov(tX,X)\n",
    "            nbrs[b*batch_size:uper] = self.Nnbrs(cor)\n",
    "            py[b*batch_size:uper] = self.predict(nbrs[b*batch_size:uper], Y[nbrs[b*batch_size:uper]])\n",
    "        #py = Variable(torch.FloatTensor(py))\n",
    "        return py\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dataset = dsets.MNIST(root='/home/yu/gits/pytorch-tutorial/tutorials/data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='/home/yu/gits/pytorch-tutorial/tutorials/data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                           batch_size=batch_size, \n",
    "#                                           shuffle=True)\n",
    "\n",
    "#test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                         batch_size=batch_size, \n",
    "#                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_dataset.train_data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = preprocessing.scale(X)\n",
    "X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train_dataset.train_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = test_dataset.test_data.numpy()\n",
    "testX = testX.reshape(testX.shape[0],-1)\n",
    "testX = preprocessing.scale(testX)\n",
    "testX = preprocessing.normalize(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_s = Variable(torch.FloatTensor([[1.]]),requires_grad=True)\n",
    "var_n = Variable(torch.FloatTensor([[1.]]),requires_grad=True)\n",
    "length_scale = Variable(torch.FloatTensor([[1.]]),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kernel = RBFkernel(var_s, var_n, length_scale)\n",
    "kernel = RBFkernel(1.,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KNN(kernel,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n",
      "1 2000\n",
      "2 3000\n",
      "3 4000\n",
      "4 5000\n",
      "5 6000\n",
      "6 7000\n",
      "7 8000\n",
      "8 9000\n",
      "9 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.831063985824585"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "tmp = model.fit_predict(testX, X,Y,batch_size=1000)\n",
    "stop = time.time()\n",
    "stop-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testY = test_dataset.test_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94059999999999999"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp==testY).sum()/10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
